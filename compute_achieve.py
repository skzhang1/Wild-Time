import numpy as np
# erm = [0.8622252390536603,0.8070550009758162,0.6722450462827859]
# erm_worst = [0.6837606837606838,0.6145251396648045,0.536741214057508]

# ft = [0.7943579811609442,0.7831102387117198,0.8028380665794678]
# ft_worst = [0.6627450980392157,0.6196078431372549,0.6843853820598007]

# lisa = [0.8414490031942814,0.863707198105954,0.8474713604022364]
# lisa_worst = [0.6871508379888268,0.723463687150838,0.6759776536312849]

# simclr = [0.7164524441627335,0.6782185826519556,0.7681644533186699]
# simclr_worst = [0.5514950166112956,0.5175718849840255,0.5897009966777409]

# swa = [0.8622252390536603,0.8070550009758162,0.6722450462827859]
# swa_worst = [0.6837606837606838,0.6145251396648045,0.536741214057508]

# print("ERM---------------------------")
# print(np.mean(erm))
# print(np.std(erm))
# print(np.mean(erm_worst))
# print("ERM---------------------------")

# print("FT---------------------------")
# print(np.mean(ft))
# print(np.std(ft))
# print(np.mean(ft_worst))
# print("FT---------------------------")

# print("lisa---------------------------")
# print(np.mean(lisa))
# print(np.std(lisa))
# print(np.mean(lisa_worst))
# print("lisa---------------------------")

# print("simclr---------------------------")
# print(np.mean(simclr))
# print(np.std(simclr))
# print(np.mean(simclr_worst))
# print("simclr---------------------------")


# print("swa---------------------------")
# print(np.mean(swa))
# print(np.std(swa))
# print(np.mean(swa_worst))
# print("swa---------------------------")


# cfo-lisa

# print(1-0.18340884831067905)
# print(1-0.3423423423423424)

# c = [0.17220933,0.34234234,0.29945799,0.19170013,0.1330076 ,0.09236525,
#  0.10608845 ,0.15730098 ,0.15620755]

# print([1-k for k in c])

###############################################################
def aggregate_to_us(inputs):
    final_result = [] 
    for i in range(9):
        tem =[]
        for k in range(i*5,min(i*5+5,len(inputs))):
            tem.append(inputs[k])
        final_result.append(np.mean(tem))
    return final_result
###############################################################

# lexico_worst

# python test.py --hpo_method lexico_worst --train_type 2 --robust_method lisa --seed 0 --device 0 --budget 10800
# [0.8353307075437627, 0.8517929848775975, 0.8662919618829918] loss_list
# 0.8511385514347841
# 0.719047619047619

# [0.86671823 0.71904762 0.76027552 0.84672021 0.90105863 0.92014498
#  0.89574911 0.88229034 0.86824233] folds


# CFO = [1-i for i in [0.14642727, 0.12630208, 0.09484127, 0.08630325, 0.12870066, 0.17840589,
#  0.25, 0.26953125, 0.16940104]]
# CFO.reverse()
# lexico_worst = [1-i for i in [0.13815789, 0.12261285, 0.08733514, 0.07929009, 0.11773575, 0.17812998,
#  0.2435462,  0.26080729, 0.16028646]]
# lexico_worst.reverse()

# print(CFO)
# print(lexico_worst)

# yearbook
# cfo = [0.83059896, 0.73046875, 0.75, 0.8215941099999999, 0.87129934, 0.91369675, 0.90515873, 0.87369792, 0.85357273]
# lexico = [0.83971354, 0.73919271, 0.7564538000000001, 0.82187002, 0.88226425, 0.92070991, 0.91266486, 0.87738715, 0.86184211] 
# cfo_lisa = [0.82779067, 0.6576576599999999, 0.7005420099999999, 0.80829987, 0.8669924, 0.90763475, 0.89391155, 0.84269902, 0.84379245]
# lexico_worst_lisa = [0.86671823 0.71904762 0.76027552 0.84672021 0.90105863 0.92014498,0.89574911 0.88229034 0.86824233] 


# mimic
# seed 1
# coral_average = [0.7643471283876015,0.8551412358736441]
# coral_worst = [0.7216494173132357,0.8499413003714076]
# coral_month = [[0.8070448394619674, 0.7216494173132357],[0.8551412358736441, 0.8499413003714076]]

########################################################## lisa ##########################################################

lisa_seed2 = [0.9242424242424242, 0.8514644351464435, 0.7571884984025559, 0.7750325097529259, 0.7008547008547008, 0.6843575418994413, 0.7158671586715867, 0.717948717948718, 0.7676609105180534, 0.686046511627907, 0.7647058823529411, 0.7145748987854251, 0.7475247524752475, 0.8203842940685045, 0.8008048289738431, 0.7948717948717948, 0.8301886792452831, 0.8555555555555555, 0.8584298584298584, 0.8689138576779026, 0.8901869158878505, 0.9300847457627118, 0.8923766816143498, 0.9135338345864662, 0.9529042386185244, 0.8896882494004796, 0.9329388560157791, 0.9337539432176656, 0.8673780487804879, 0.8624454148471615, 0.9298245614035088, 0.9079497907949791, 0.9075425790754258, 0.860236220472441, 0.8257918552036199, 0.7857142857142857, 0.8518518518518519, 0.9150326797385621, 0.8831683168316832, 0.8387715930902111, 0.7701149425287356, 0.8571428571428571, 0.9087221095334685]
seed2 = [0.8017565136798102, 0.7143761681331413, 0.7695989313311922, 0.8415919491560789, 0.9158172832939806, 0.8972409024523147, 0.8862690013899949, 0.8549077454453187, 0.845326636401687]
lisa_seed3 = [0.9141414141414141, 0.803347280334728, 0.7220447284345048, 0.7347204161248374, 0.6666666666666666, 0.6703910614525139, 0.6918819188191881, 0.7393162393162394, 0.7551020408163265, 0.6578073089700996, 0.7176470588235294, 0.6821862348178138, 0.7103960396039604, 0.8011695906432749, 0.7867203219315896, 0.7728937728937729, 0.8490566037735849, 0.8583333333333333, 0.8352638352638353, 0.83270911360799, 0.8644859813084113, 0.9110169491525424, 0.874439461883408, 0.924812030075188, 0.9372056514913658, 0.8920863309352518, 0.9585798816568047, 0.9400630914826499, 0.9009146341463414, 0.8864628820960698, 0.9441786283891547, 0.9372384937238494, 0.9099756690997567, 0.889763779527559, 0.834841628959276, 0.8, 0.8765432098765432, 0.9215686274509803, 0.8950495049504951, 0.8598848368522073, 0.735632183908046, 0.753968253968254, 0.9168356997971603]
seed3 = [0.7681841011404302, 0.7028997138748735, 0.7396238491640337, 0.8296513317745033, 0.902392014782183, 0.9156213640634234, 0.903199639939919, 0.8706092358260452, 0.8021453792244868]
lisa_seed4 = [0.9393939393939394, 0.8472803347280334, 0.7955271565495208, 0.7737321196358907, 0.6862026862026862, 0.6620111731843575, 0.6826568265682657, 0.7393162393162394, 0.7629513343799058, 0.6777408637873754, 0.7411764705882353, 0.6740890688259109, 0.7301980198019802, 0.8036758563074352, 0.7867203219315896, 0.8205128205128205, 0.8850771869639794, 0.8361111111111111, 0.8944658944658944, 0.8726591760299626, 0.8925233644859814, 0.9322033898305084, 0.9192825112107623, 0.9548872180451128, 0.945054945054945, 0.920863309352518, 0.960552268244576, 0.9589905362776026, 0.8765243902439024, 0.888646288209607, 0.9362041467304625, 0.9386331938633193, 0.9099756690997567, 0.8385826771653543, 0.8371040723981901, 0.8285714285714286, 0.8930041152263375, 0.9084967320261438, 0.900990099009901, 0.8426103646833013, 0.7241379310344828, 0.8571428571428571, 0.9148073022312373]
seed4 = [0.8084272473020141, 0.7049352874472288, 0.7471719474910302, 0.8617652378167536, 0.928790285725462, 0.9211153584656412, 0.8920999518514166, 0.8747345479034223, 0.8320293634695256]

average = []
average.append(np.mean(seed2))
average.append(np.mean(seed3))
average.append(np.mean(seed4))
print(np.mean(average))

worst = []
worst.append(min(seed2))
worst.append(min(seed3))
worst.append(min(seed4))
print(np.mean(worst))

folds = []
folds.append(aggregate_to_us(lisa_seed2))
folds.append(aggregate_to_us(lisa_seed3))
folds.append(aggregate_to_us(lisa_seed4))
print(np.mean(folds,axis=0))

########################################################## lisa ##########################################################

